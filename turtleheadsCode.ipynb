{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plant Specimen Image Classification\n",
    "Description\n",
    "Help advance biodiversity research by building an ML model to categorize plant specimen images, for the New York Botanical Garden. Using image classification machine learning techniques to train a model capable of distinguishing among the image classes represented in this dataset (i.e., sorting images into classes) with a high level of accuracy.\n",
    "\n",
    "Problem\n",
    "Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"BTTAIxNYBG-train.csv\")\n",
    "validate_df = pd.read_csv(\"BTTAIxNYBG-validation.csv\")\n",
    "test_df = pd.read_csv(\"BTTAIxNYBG-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset & Define image directory\n",
    "train_image_directory = 'BTTAIxNYBG-train/BTTAIxNYBG-train/'\n",
    "validate_image_directory = 'BTTAIxNYBG-validation/BTTAIxNYBG-validation/' \n",
    "test_image_directory = 'BTTAIxNYBG-test/BTTAIxNYBG-test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to load and process images\n",
    "def train_load_and_preprocess_image(filename, target_size=(224, 224)):\n",
    "    img_path = os.path.join(train_image_directory, filename)\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Model expects a batch of images\n",
    "    return img_array / 255.0  # Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to load and process images\n",
    "def validate_load_and_preprocess_image(filename, target_size=(224, 224)):\n",
    "    img_path = os.path.join(validate_image_directory, filename)\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Model expects a batch of images\n",
    "    return img_array / 255.0  # Normalize to [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df[:5000]\n",
    "validate_df=validate_df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to all images\n",
    "train_df['imageData'] = train_df['imageFile'].apply(train_load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df['imageData'] = validate_df['imageFile'].apply(validate_load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>classLabel</th>\n",
       "      <th>classID</th>\n",
       "      <th>source</th>\n",
       "      <th>imageFile</th>\n",
       "      <th>imageData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>K</td>\n",
       "      <td>f09a8abe9e9e9ef2.jpg</td>\n",
       "      <td>[[[[0.02745098 0.03137255 0.04705882], [0.0274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>BHL</td>\n",
       "      <td>a6c6868387c6af8c.jpg</td>\n",
       "      <td>[[[[0.78039217 0.67058825 0.5254902 ], [0.7803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>ordinary-pressed-specimens</td>\n",
       "      <td>9</td>\n",
       "      <td>YU</td>\n",
       "      <td>6062c68e8c34b292.jpg</td>\n",
       "      <td>[[[[0.2509804  0.23529412 0.23921569], [0.2666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>animal-specimens</td>\n",
       "      <td>0</td>\n",
       "      <td>CAS</td>\n",
       "      <td>363617271597dfd9.jpg</td>\n",
       "      <td>[[[[0.52156866 0.5019608  0.49019608], [0.5215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>biocultural-specimens</td>\n",
       "      <td>1</td>\n",
       "      <td>Met</td>\n",
       "      <td>4218d8d2f42b05e4.jpg</td>\n",
       "      <td>[[[[0.32156864 0.3137255  0.31764707], [0.3215...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                  classLabel  classID source             imageFile  \\\n",
       "0         7           microscope-slides        6      K  f09a8abe9e9e9ef2.jpg   \n",
       "1        20         illustrations-color        2    BHL  a6c6868387c6af8c.jpg   \n",
       "2        37  ordinary-pressed-specimens        9     YU  6062c68e8c34b292.jpg   \n",
       "3        59            animal-specimens        0    CAS  363617271597dfd9.jpg   \n",
       "4        60       biocultural-specimens        1    Met  4218d8d2f42b05e4.jpg   \n",
       "\n",
       "                                           imageData  \n",
       "0  [[[[0.02745098 0.03137255 0.04705882], [0.0274...  \n",
       "1  [[[[0.78039217 0.67058825 0.5254902 ], [0.7803...  \n",
       "2  [[[[0.2509804  0.23529412 0.23921569], [0.2666...  \n",
       "3  [[[[0.52156866 0.5019608  0.49019608], [0.5215...  \n",
       "4  [[[[0.32156864 0.3137255  0.31764707], [0.3215...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split dataset into training and validation sets\n",
    "# ### Note: This is a common step in ML training, but in this challenge, since the validation set is provided separately, there is no need to call this function to distinguish between validation and train set.\n",
    "# # train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Data augmentation configuration for training\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # Note: No augmentation for validation data, only rescaling\n",
    "# validation_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert dataframe to a format suitable for the model training\n",
    "# def train_df_to_dataset(dataframe, datagen, batch_size=32):\n",
    "#     datagen.flow_from_dataframe(\n",
    "#         dataframe=dataframe,\n",
    "#         directory=train_image_directory,\n",
    "#         x_col='imageFile',\n",
    "#         y_col='classLabel',\n",
    "#         target_size=(256, 256),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical'  # Change this if not a multiclass classification\n",
    "#     )\n",
    "\n",
    "# def validate_df_to_dataset(dataframe, datagen, batch_size=32):\n",
    "#     datagen.flow_from_dataframe(\n",
    "#         dataframe=dataframe,\n",
    "#         directory=validate_image_directory,\n",
    "#         x_col='imageFile',\n",
    "#         y_col='classLabel',\n",
    "#         target_size=(256, 256),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical'  # Change this if not a multiclass classification\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create datasets for training and validation\n",
    "# train_dataset = train_df_to_dataset(split_train_df, datagen)\n",
    "# validation_dataset = validate_df_to_dataset(validate_df, datagen)\n",
    "\n",
    "# # This setup is now ready for training with model.fit using the train_dataset and validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "validate_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "# validate_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames belonging to 10 classes.\n",
      "Found 5000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=train_image_directory,\n",
    "    x_col='imageFile',\n",
    "    y_col='classLabel',\n",
    "    # subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",  \n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=validate_df,\n",
    "    directory=validate_image_directory,\n",
    "    x_col='imageFile',\n",
    "    y_col='classLabel',\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30690 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_image_directory,\n",
    "    x_col='imageFile',\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    target_size=(224, 224)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 222, 222, 32)      9248      \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 222, 222, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 111, 111, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 111, 111, 32)      0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 111, 111, 64)      18496     \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 111, 111, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 55, 55, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 55, 55, 64)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 193600)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               49561856  \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49593066 (189.18 MB)\n",
      "Trainable params: 49593066 (189.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(224,224,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     # tf.keras.layers.RandomRotation(.25, input_shape=[256,256,1]),\n",
    "#     tf.keras.layers.Conv2D(64, 7, padding=\"same\", input_shape=[224,224,1]),\n",
    "#     tf.keras.layers.MaxPooling2D(2),\n",
    "#     tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2),\n",
    "#     # tf.keras.layers.Conv2D(256, 3, padding=\"same\", activation='relu'),\n",
    "#     # tf.keras.layers.Conv2D(256, 3, padding=\"same\", activation='relu'),\n",
    "#     # tf.keras.layers.MaxPooling2D(2),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "# ])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(256, kernel_size=(3,3), activation='relu',input_shape=(224,224,3)))\n",
    "# model.add(MaxPooling2D(2,2))\n",
    "# model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "# model.add(MaxPooling2D(2,2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "# model.fit_generator(generator=train_generator,\n",
    "#                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=STEP_SIZE_VALID,\n",
    "#                     epochs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=5\n",
    "# history = model.fit(\n",
    "#   train_generator,\n",
    "#   validation_data=valid_generator,\n",
    "#   epochs=epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_dataset, epochs=10, validation_data=(validation_dataset), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 753s 5s/step - loss: 2.3322 - accuracy: 0.3496 - val_loss: 1.1926 - val_accuracy: 0.6470\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 792s 5s/step - loss: 0.9896 - accuracy: 0.6564 - val_loss: 0.7065 - val_accuracy: 0.7858\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 21463s 138s/step - loss: 0.6408 - accuracy: 0.7712 - val_loss: 0.5749 - val_accuracy: 0.8132\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 16477s 106s/step - loss: 0.4906 - accuracy: 0.8282 - val_loss: 0.5219 - val_accuracy: 0.8120\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 1271s 8s/step - loss: 0.3643 - accuracy: 0.8714 - val_loss: 0.5411 - val_accuracy: 0.8094\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 1115s 7s/step - loss: 0.2743 - accuracy: 0.9062 - val_loss: 0.5455 - val_accuracy: 0.8244\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 1175s 7s/step - loss: 0.2105 - accuracy: 0.9300 - val_loss: 0.5372 - val_accuracy: 0.8308\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 852s 5s/step - loss: 0.1909 - accuracy: 0.9328 - val_loss: 0.5018 - val_accuracy: 0.8446\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 738s 5s/step - loss: 0.1549 - accuracy: 0.9446 - val_loss: 0.5408 - val_accuracy: 0.8374\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 266s 2s/step - loss: 0.1172 - accuracy: 0.9598 - val_loss: 0.5371 - val_accuracy: 0.8484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c6ea7460>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=10, validation_data=(valid_generator), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_generator, epochs=10, steps_per_epoch=subset_size//batch_size, validation_data=valid_generator,\n",
    "#                     validation_steps=subset_size//batch_size) #, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 73s 461ms/step - loss: 0.5371 - accuracy: 0.8484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8483999967575073"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(valid_generator)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 474s 494ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_error(prediction, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 221s 230ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss, accuracy = model.evaluate(test_generator)\n",
    "# accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'uniqueID': test_df['uniqueID'], 'classID': prediction.argmax(axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['uniqueID', 'classID']].to_csv(\"submission.csv\")\n",
    "#y_pred.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
