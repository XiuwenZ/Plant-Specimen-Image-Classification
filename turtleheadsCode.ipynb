{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maryhe/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"BTTAIxNYBG-train.csv\")\n",
    "validate_df = pd.read_csv(\"BTTAIxNYBG-validation.csv\")\n",
    "test_df = pd.read_csv(\"BTTAIxNYBG-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset & Define image directory\n",
    "train_image_directory = 'BTTAIxNYBG-train/BTTAIxNYBG-train/'\n",
    "validate_image_directory = 'BTTAIxNYBG-validation/BTTAIxNYBG-validation/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_df=train_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to load and process images\n",
    "def train_load_and_preprocess_image(filename, target_size=(256, 256)):\n",
    "    img_path = os.path.join(train_image_directory, filename)\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Model expects a batch of images\n",
    "    return img_array / 255.0  # Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to load and process images\n",
    "def validate_load_and_preprocess_image(filename, target_size=(256, 256)):\n",
    "    img_path = os.path.join(validate_image_directory, filename)\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Model expects a batch of images\n",
    "    return img_array / 255.0  # Normalize to [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/zr75ng851t33cs9hvh9_n1h00000gn/T/ipykernel_3106/3133558908.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_train_df['imageData'] = split_train_df['imageFile'].apply(train_load_and_preprocess_image)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to all images\n",
    "split_train_df['imageData'] = split_train_df['imageFile'].apply(train_load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df['imageData'] = validate_df['imageFile'].apply(validate_load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and validation sets\n",
    "### Note: This is a common step in ML training, but in this challenge, since the validation set is provided separately, there is no need to call this function to distinguish between validation and train set.\n",
    "# train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation configuration for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Note: No augmentation for validation data, only rescaling\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to a format suitable for the model training\n",
    "def train_df_to_dataset(dataframe, datagen, batch_size=32):\n",
    "    datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        directory=train_image_directory,\n",
    "        x_col='imageFile',\n",
    "        y_col='classLabel',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'  # Change this if not a multiclass classification\n",
    "    )\n",
    "\n",
    "def validate_df_to_dataset(dataframe, datagen, batch_size=32):\n",
    "    datagen.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        directory=validate_image_directory,\n",
    "        x_col='imageFile',\n",
    "        y_col='classLabel',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'  # Change this if not a multiclass classification\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 validated image filenames belonging to 10 classes.\n",
      "Found 10244 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create datasets for training and validation\n",
    "train_dataset = train_df_to_dataset(split_train_df, datagen)\n",
    "validation_dataset = validate_df_to_dataset(validate_df, datagen)\n",
    "\n",
    "# This setup is now ready for training with model.fit using the train_dataset and validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 validated image filenames belonging to 10 classes.\n",
      "Found 2561 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=split_train_df,\n",
    "    directory=train_image_directory,\n",
    "    x_col='imageFile',\n",
    "    y_col='classLabel',\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",  \n",
    "    target_size=(256, 256)\n",
    ")\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=validate_df,\n",
    "    directory=validate_image_directory,\n",
    "    x_col='imageFile',\n",
    "    y_col='classLabel',\n",
    "    subset=\"validation\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(256, 256)\n",
    ")\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.preprocessing.image.DataFrameIterator at 0x17537ff40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 256, 256, 32)      320       \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 254, 254, 32)      9248      \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 254, 254, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 127, 127, 32)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 127, 127, 32)      0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 127, 127, 64)      18496     \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 127, 127, 64)      0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 125, 125, 64)      36928     \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 125, 125, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 62, 62, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 62, 62, 64)        0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 246016)            0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               125960704 \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126030826 (480.77 MB)\n",
      "Trainable params: 126030826 (480.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(256,256,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " random_rotation_1 (RandomR  (None, 256, 256, 1)       0         \n",
      " otation)                                                        \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 256, 256, 64)      3200      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 128, 128, 64)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 64, 64, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 524288)            0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               67108992  \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67342538 (256.89 MB)\n",
      "Trainable params: 67342538 (256.89 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.RandomRotation(.25, input_shape=[256,256,1]),\n",
    "#     tf.keras.layers.Conv2D(64, 7, padding=\"same\", activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2),\n",
    "#     tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2),\n",
    "#     # tf.keras.layers.Conv2D(256, 3, padding=\"same\", activation='relu'),\n",
    "#     # tf.keras.layers.Conv2D(256, 3, padding=\"same\", activation='relu'),\n",
    "#     # tf.keras.layers.MaxPooling2D(2),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "# ])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu',input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "# model.fit_generator(generator=train_generator,\n",
    "#                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=STEP_SIZE_VALID,\n",
    "#                     epochs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_list = ['uniqueID', 'classLabel', 'source', 'imageFile', 'imageData']\n",
    "# target = validate_df['classID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = validate_df['classID']\n",
    "# X = validate_df[feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = validation_dataset.drop('classID', axis=1), validation_dataset['classID']\n",
    "# X_test, y_test = train_dataset.drop('classID', axis=1), train_dataset['classID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = train_df['classID']\n",
    "# X = train_df.drop(['classID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai import *\n",
    "# from fastai.vision import *\n",
    "# from fastai.metrics import error_rate\n",
    "# from fastai.vision.all import *\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path=\"BTTAIxNYBG-train.csv\"\n",
    "# valid_path=\"BTTAIxNYBG-validation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = datablock.dataloaders([train_path, valid_path], splitter=GrandparentSplitter(train_name='train', valid_name='valid'))\n",
    "\n",
    "# learn = cnn_learner(data, models.resnet34, metrics=[accuracy], model_dir = Path('../kaggle/working'),path = Path(\".\"))\n",
    "# learn = vision_learner(validate_df, models.resnet34, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/maryhe/Documents/BTT AI/Turtleheads/bttai-nybg-2024/turtleheadsCode.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maryhe/Documents/BTT%20AI/Turtleheads/bttai-nybg-2024/turtleheadsCode.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(validation_dataset), batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1102\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1103\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1104\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m     )\n\u001b[1;32m   1110\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1111\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1115\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10, validation_data=(validation_dataset), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 1046, in launch_instance\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 736, in start\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/var/folders/t0/zr75ng851t33cs9hvh9_n1h00000gn/T/ipykernel_3106/631605186.py\", line 1, in <module>\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/backend.py\", line 5777, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [14,3] and labels shape [140]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_7416]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/maryhe/Documents/BTT AI/Turtleheads/bttai-nybg-2024/turtleheadsCode.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maryhe/Documents/BTT%20AI/Turtleheads/bttai-nybg-2024/turtleheadsCode.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(valid_generator), batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 1046, in launch_instance\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 736, in start\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/var/folders/t0/zr75ng851t33cs9hvh9_n1h00000gn/T/ipykernel_3106/631605186.py\", line 1, in <module>\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/Users/maryhe/Library/Python/3.9/lib/python/site-packages/keras/src/backend.py\", line 5777, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [14,3] and labels shape [140]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_7416]"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=10, validation_data=(valid_generator), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_proba = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['uniqueID', 'classID']].to_csv(\"output.csv\")\n",
    "#y_pred.to_csv(\"o\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
