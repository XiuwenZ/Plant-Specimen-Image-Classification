{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plant Specimen Image Classification\n",
    "Description\n",
    "Help advance biodiversity research by building an ML model to categorize plant specimen images, for the New York Botanical Garden. Using image classification machine learning techniques to train a model capable of distinguishing among the image classes represented in this dataset (i.e., sorting images into classes) with a high level of accuracy.\n",
    "\n",
    "Problem\n",
    "Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"BTTAIxNYBG-train.csv\")\n",
    "validate_df = pd.read_csv(\"BTTAIxNYBG-validation.csv\")\n",
    "test_df = pd.read_csv(\"BTTAIxNYBG-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset & Define image directory\n",
    "train_image_directory = 'BTTAIxNYBG-train/BTTAIxNYBG-train/'\n",
    "validate_image_directory = 'BTTAIxNYBG-validation/BTTAIxNYBG-validation/' \n",
    "test_image_directory = 'BTTAIxNYBG-test/BTTAIxNYBG-test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to load and process images\n",
    "def train_load_and_preprocess_image(filename, target_size=(224, 224)):\n",
    "    img_path = os.path.join(train_image_directory, filename)\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Model expects a batch of images\n",
    "    return img_array / 255.0  # Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to load and process images\n",
    "def validate_load_and_preprocess_image(filename, target_size=(224, 224)):\n",
    "    img_path = os.path.join(validate_image_directory, filename)\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Model expects a batch of images\n",
    "    return img_array / 255.0  # Normalize to [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df[:5000]\n",
    "validate_df=validate_df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/zr75ng851t33cs9hvh9_n1h00000gn/T/ipykernel_18472/3133558908.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  split_train_df['imageData'] = split_train_df['imageFile'].apply(train_load_and_preprocess_image)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to all images\n",
    "train_df['imageData'] = train_df['imageFile'].apply(train_load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df['imageData'] = validate_df['imageFile'].apply(validate_load_and_preprocess_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>classLabel</th>\n",
       "      <th>classID</th>\n",
       "      <th>source</th>\n",
       "      <th>imageFile</th>\n",
       "      <th>imageData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>microscope-slides</td>\n",
       "      <td>6</td>\n",
       "      <td>K</td>\n",
       "      <td>f09a8abe9e9e9ef2.jpg</td>\n",
       "      <td>[[[[0.02745098 0.03137255 0.04705882], [0.0274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>illustrations-color</td>\n",
       "      <td>2</td>\n",
       "      <td>BHL</td>\n",
       "      <td>a6c6868387c6af8c.jpg</td>\n",
       "      <td>[[[[0.78039217 0.67058825 0.5254902 ], [0.7803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>ordinary-pressed-specimens</td>\n",
       "      <td>9</td>\n",
       "      <td>YU</td>\n",
       "      <td>6062c68e8c34b292.jpg</td>\n",
       "      <td>[[[[0.2509804  0.23529412 0.23921569], [0.2666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>animal-specimens</td>\n",
       "      <td>0</td>\n",
       "      <td>CAS</td>\n",
       "      <td>363617271597dfd9.jpg</td>\n",
       "      <td>[[[[0.52156866 0.5019608  0.49019608], [0.5215...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>biocultural-specimens</td>\n",
       "      <td>1</td>\n",
       "      <td>Met</td>\n",
       "      <td>4218d8d2f42b05e4.jpg</td>\n",
       "      <td>[[[[0.32156864 0.3137255  0.31764707], [0.3215...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                  classLabel  classID source             imageFile  \\\n",
       "0         7           microscope-slides        6      K  f09a8abe9e9e9ef2.jpg   \n",
       "1        20         illustrations-color        2    BHL  a6c6868387c6af8c.jpg   \n",
       "2        37  ordinary-pressed-specimens        9     YU  6062c68e8c34b292.jpg   \n",
       "3        59            animal-specimens        0    CAS  363617271597dfd9.jpg   \n",
       "4        60       biocultural-specimens        1    Met  4218d8d2f42b05e4.jpg   \n",
       "\n",
       "                                           imageData  \n",
       "0  [[[[0.02745098 0.03137255 0.04705882], [0.0274...  \n",
       "1  [[[[0.78039217 0.67058825 0.5254902 ], [0.7803...  \n",
       "2  [[[[0.2509804  0.23529412 0.23921569], [0.2666...  \n",
       "3  [[[[0.52156866 0.5019608  0.49019608], [0.5215...  \n",
       "4  [[[[0.32156864 0.3137255  0.31764707], [0.3215...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split dataset into training and validation sets\n",
    "# ### Note: This is a common step in ML training, but in this challenge, since the validation set is provided separately, there is no need to call this function to distinguish between validation and train set.\n",
    "# # train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Data augmentation configuration for training\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # Note: No augmentation for validation data, only rescaling\n",
    "# validation_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert dataframe to a format suitable for the model training\n",
    "# def train_df_to_dataset(dataframe, datagen, batch_size=32):\n",
    "#     datagen.flow_from_dataframe(\n",
    "#         dataframe=dataframe,\n",
    "#         directory=train_image_directory,\n",
    "#         x_col='imageFile',\n",
    "#         y_col='classLabel',\n",
    "#         target_size=(256, 256),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical'  # Change this if not a multiclass classification\n",
    "#     )\n",
    "\n",
    "# def validate_df_to_dataset(dataframe, datagen, batch_size=32):\n",
    "#     datagen.flow_from_dataframe(\n",
    "#         dataframe=dataframe,\n",
    "#         directory=validate_image_directory,\n",
    "#         x_col='imageFile',\n",
    "#         y_col='classLabel',\n",
    "#         target_size=(256, 256),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical'  # Change this if not a multiclass classification\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create datasets for training and validation\n",
    "# train_dataset = train_df_to_dataset(split_train_df, datagen)\n",
    "# validation_dataset = validate_df_to_dataset(validate_df, datagen)\n",
    "\n",
    "# # This setup is now ready for training with model.fit using the train_dataset and validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "validate_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "# validate_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 validated image filenames belonging to 10 classes.\n",
      "Found 1000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=train_image_directory,\n",
    "    x_col='imageFile',\n",
    "    y_col='classLabel',\n",
    "    # subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",  \n",
    "    target_size=(224, 224)\n",
    ")\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=validate_df,\n",
    "    directory=validate_image_directory,\n",
    "    x_col='imageFile',\n",
    "    y_col='classLabel',\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(224, 224)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_image_directory,\n",
    "    x_col='imageFile',\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    target_size=(224, 224)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 222, 222, 32)      9248      \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 222, 222, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 111, 111, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 111, 111, 32)      0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 111, 111, 64)      18496     \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 111, 111, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 55, 55, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 55, 55, 64)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 193600)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               49561856  \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49593066 (189.18 MB)\n",
      "Trainable params: 49593066 (189.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(224,224,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     # tf.keras.layers.RandomRotation(.25, input_shape=[256,256,1]),\n",
    "#     tf.keras.layers.Conv2D(64, 7, padding=\"same\", input_shape=[224,224,1]),\n",
    "#     tf.keras.layers.MaxPooling2D(2),\n",
    "#     tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2),\n",
    "#     # tf.keras.layers.Conv2D(256, 3, padding=\"same\", activation='relu'),\n",
    "#     # tf.keras.layers.Conv2D(256, 3, padding=\"same\", activation='relu'),\n",
    "#     # tf.keras.layers.MaxPooling2D(2),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "# ])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(256, kernel_size=(3,3), activation='relu',input_shape=(224,224,3)))\n",
    "# model.add(MaxPooling2D(2,2))\n",
    "# model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "# model.add(MaxPooling2D(2,2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "# STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "# model.fit_generator(generator=train_generator,\n",
    "#                     steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "#                     validation_data=valid_generator,\n",
    "#                     validation_steps=STEP_SIZE_VALID,\n",
    "#                     epochs=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=5\n",
    "# history = model.fit(\n",
    "#   train_generator,\n",
    "#   validation_data=valid_generator,\n",
    "#   epochs=epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_dataset, epochs=10, validation_data=(validation_dataset), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 124s 4s/step - loss: 6.4029 - accuracy: 0.1480 - val_loss: 2.1963 - val_accuracy: 0.1450\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 108s 3s/step - loss: 1.9566 - accuracy: 0.2770 - val_loss: 1.7893 - val_accuracy: 0.3920\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 110s 3s/step - loss: 1.6573 - accuracy: 0.3970 - val_loss: 1.4747 - val_accuracy: 0.5460\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 132s 4s/step - loss: 1.3955 - accuracy: 0.5320 - val_loss: 1.4380 - val_accuracy: 0.5780\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 231s 7s/step - loss: 1.2814 - accuracy: 0.5570 - val_loss: 1.2047 - val_accuracy: 0.6190\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 9087s 293s/step - loss: 0.9985 - accuracy: 0.6680 - val_loss: 1.1136 - val_accuracy: 0.6520\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 13172s 425s/step - loss: 0.7910 - accuracy: 0.7180 - val_loss: 0.9993 - val_accuracy: 0.6650\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 547s 17s/step - loss: 0.6260 - accuracy: 0.7940 - val_loss: 0.9403 - val_accuracy: 0.6780\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 3636s 117s/step - loss: 0.5320 - accuracy: 0.8150 - val_loss: 0.8835 - val_accuracy: 0.6930\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 4565s 147s/step - loss: 0.4201 - accuracy: 0.8660 - val_loss: 0.8867 - val_accuracy: 0.7170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c3097eb0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=10, validation_data=(valid_generator), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(train_generator, epochs=10, steps_per_epoch=subset_size//batch_size, validation_data=valid_generator,\n",
    "#                     validation_steps=subset_size//batch_size) #, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1087s 35s/step - loss: 0.8867 - accuracy: 0.7170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7170000076293945"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(valid_generator)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 954s 31s/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_error(prediction, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 679s 22s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'uniqueID': test_df['uniqueID'], 'classID': prediction.argmax(axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_proba = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['uniqueID', 'classID']].to_csv(\"output.csv\")\n",
    "#y_pred.to_csv(\"o\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
